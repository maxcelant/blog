{"index":{"slug":"index","filePath":"index.md","title":"Hi There üëã","links":["www.github.com/maxcelant","www.linkedin/in/maxcelant"],"tags":[],"content":"My name is Massimiliano (Max), I currently work at American Airlines as a Platform Engineer on the Kubernetes as a Platform team.\nMore specifically, I work on the Kubernetes operators squad where we help support over 300 American Airlines applications.\nI like to dive into different tech related topics on my free time and read technical books. I‚Äôm going to use this space to expand on my\nlearning and dive into interesting topics I want to get a better grasp of.\nI‚Äôm not anti-AI, but I won‚Äôt be using it to assist my writing. I feel like that defeats the purpose of writing a blog.\nIf you are interested in following me:\n\nGithub\nLinkedin\n"},"posts/runner-orchestration-in-controller-runtime":{"slug":"posts/runner-orchestration-in-controller-runtime","filePath":"posts/runner-orchestration-in-controller-runtime.md","title":"Controller Orchestration Model in Controller Runtime Library","links":[],"tags":[],"content":"The controller-runtime library is utilized by numerous controller builders and templating engines (Kubebuilder, Operator SDK to name a few) to standardize the management of Kubernetes controllers. It handles the lifecycle of these controllers as well as webhooks, caches, servers and more while offering a fairly simple interface to build your operator on top of through it‚Äôs Reconciler.\nI‚Äôve been curious about how it works internally and decided to start diving into how the Manager handles the life-cycle of all these runnables.\nTo clarify,Runnable is just a simple interface with a Start function which controllers, webhooks, caches and more all implement.\ntype Runnable interface {\n\tStart(context.Context) error\n}\nDigging a bit deeper, you‚Äôll notice that the manager splits these runnables by functionality into runnableGroups, so that like-minded objects can be added, reconciled, and shutdown together. For instance, the way webhooks are handled internally is completely different from a leader elected controller, yet the life-cycle can be handled the same‚Äîthey all need to start and stop.\nEach runnable spins off into it‚Äôs own goroutine so that all of the runnables can do their jobs at the same time. The question then becomes, how exactly does the manager effectively orchestrate the lifetime of these runnables? Let‚Äôs take a closer look:\nStep by Step\n\n\nThe Start function starts by using first encapsulating the logic in a sync.Once callback called startOnce, to ensure the inside only runs one time.\nfunc (r *runnableGroup) Start(ctx context.Context) error {\n\tvar retErr error\n \n\tr.startOnce.Do(func() {\n        ...\n\n\nWe kick off a goroutine withr.reconcile . This is the internal reconciler that initiates all of the runnables. You‚Äôll see very shortly how it works.\ngo r.reconcile()\n\n\nWe attain the lock, mark the group as started and mark each runnable in the group as ready to start (Keep signalReady in mind, it‚Äôll come up later) and add it to the runnable dispatch channel simply called ch.\nr.start.Lock()\nr.started = true\nfor _, rn := range r.startQueue {\n\trn.signalReady = true\n\tr.ch &lt;- rn\n}\nr.start.Unlock()\n\n\nIf there is nothing in the start queue, we return from Start. There‚Äôs nothing to run, so there‚Äôs nothing to do.\nif len(r.startQueue) == 0 {\n\treturn\n}\n\n\nThis next section involves coordination with the reconcile method which we recently started in it‚Äôs own goroutine in step 2, so let‚Äôs look at that method first. We start by reading off of the dispatch channel ch which we filled in step 3.\nfunc (r *runnableGroup) reconcile() {\n\tfor runnable := range r.ch {\n\t\t...\n\n\nThe first thing we do in the loop is very important. Part of the interesting bit to this logic is that the manager can support adding new runnables after having already started. With that in mind, we only want to add the runnable to the wait group if the manager is not in shutdown sequence. The reason is that executing wg.Add after wg.Wait is called will cause the program to panic.\nwg.Wait is a blocking call that waits for the wait group to decrement back to 0, so calling wg.Add after doesn‚Äôt make any sense‚Äîhence the panic.\nSo in the chance we are in shutdown, we continue and avoid adding the runner.\n{\n\tr.stop.RLock()\n\tif r.stopped {\n\t\tr.errChan &lt;- errRunnableGroupStopped\n\t\tr.stop.RUnlock()\n\t\tcontinue\n\t}\n\tr.wg.Add(1)\n\tr.stop.RUnlock()\n}\n\n\nThis is the portion that actually starts the individual runnable. There are some important aspects to look at. First, you‚Äôll notice this whole section is nested in a goroutine, that‚Äôs because each runnable runs in parallel.\nAnother interesting bit is the nested goroutine. This block acts as a signaler back to the Start method, telling it ‚ÄúHey, this runnable has started.‚Äù It‚Äôs put it it‚Äôs own thread so that it‚Äôs non-blocking to the actual start of the runnable. It signals by sending the runnable into the startReadyCh which the Start method is ready to receive from.\nLastly, we make sure to defer wg.Done() to ensure that this runnable is correctly checked off in the shutdown process (decrementing that counter we spoke of previously).\ngo func(rn *readyRunnable) {\n\t// Signal back to Start method\n\tgo func() {\n\t\tif rn.Check(r.ctx) {\n\t\t\tif rn.signalReady {\n\t\t\t\tr.startReadyCh &lt;- rn\n\t\t\t}\n\t\t}\n\t}()\n \n\tdefer r.wg.Done()\n \n\t// Start the runnable\n\tif err := rn.Start(r.ctx); err != nil {\n\t\tr.errChan &lt;- err\n\t}\n}(runnable)\n\n\nGoing back to the Start method, we can see the relationship it has with reconcile.\nfor {\n\tselect {\n\tcase &lt;-ctx.Done():\n\t\tif err := ctx.Err(); !errors.Is(err, context.Canceled) {\n\t\t\tretErr = err\n\t\t}\n\t// Remove the runnable from the queue\n\tcase rn := &lt;-r.startReadyCh:\n\t\tfor i, existing := range r.startQueue {\n\t\t\tif existing == rn {\n\t\t\t\tr.startQueue = append(r.startQueue[:i], r.startQueue[i+1:]...)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif len(r.startQueue) == 0 {\n\t\t\treturn\n\t\t}\n\t}\n}\nWe read runnables off of the startReadyCh channel which sent the runnable down the pipe in step 7. We find it and eliminate it from the startQueue. Once the start queue is empty, we can finally quit out of the Start method because we‚Äôve successfully launched all of our runnables!\nNow, let‚Äôs now see how the shutdown process handles these runnables when we decide to stop the manager.\n\n\nShutdown is signaled through the StopAndWait method. Once again we use sync.Once to execute the section exactly once.\nfunc (r *runnableGroup) StopAndWait(ctx context.Context) {\n\tr.stopOnce.Do(func() {\n\t\t...\n\n\nWe first defer the closing of the dispatch ch channel, we don‚Äôt want any more runnables being added and spun up during the termination process.\ndefer func() {\n\tr.stop.Lock()\n\tclose(r.ch)\n\tr.stop.Unlock()\n}()\n\n\nNext we internally call Start, this might seem backwards at first, but we trigger it here to ensure we kick off the reconcile loop and consume the r.ch channel. We want to clear any runnables in the queue and ensure the wait group is back to 0.\n_ = r.Start(ctx)\nr.stop.Lock()\n// Store the stopped variable so we don&#039;t accept any new\n// runnables for the time being.\nr.stopped = true\nr.stop.Unlock()\n\n\nThe context is passed into all the runnables in step 7 line 12, so by calling cancel here, we are effectively signaling to all the runnables, ‚ÄúThe shutdown process is in effect, please stop your reconcile loops‚Äù, which causes those runnable loops to break and exit.\n// Cancel the internal channel.\nr.cancel()\n\n\nHere we have an interesting concurrency pattern at play. This pattern let‚Äôs us either wait for the wait group to complete, i.e, reach 0 or wait for a set timer to expire. This pattern is ideal because it achieves flexibility by creating multiple exit conditions.\ndone := make(chan struct{})\ngo func() {\n\tdefer close(done)\n\tr.wg.Wait()\n}()\n \nselect {\ncase &lt;-done:\n\t// We&#039;re done, exit.\ncase &lt;-ctx.Done():\n\t// Calling context has expired, exit.\n}\n\n\nAnd there you have it! The complete controller lifecycle orchestrated by the manager in controller-runtime. Feel free to view the code in it‚Äôs entirety here."}}